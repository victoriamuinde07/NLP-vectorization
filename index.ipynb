{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing tokenization and count vectorization from scratch \n",
    "\n",
    "Implementing TF-IDF from scratch \n",
    "\n",
    "Using dimensionality reduction on vectorized text data to create and interpret visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['song1.txt',\n",
       " 'song2.txt',\n",
       " 'song3.txt',\n",
       " 'song4.txt',\n",
       " 'song5.txt',\n",
       " 'song6.txt',\n",
       " 'song7.txt',\n",
       " 'song8.txt',\n",
       " 'song9.txt',\n",
       " 'song10.txt',\n",
       " 'song11.txt',\n",
       " 'song12.txt',\n",
       " 'song13.txt',\n",
       " 'song14.txt',\n",
       " 'song15.txt',\n",
       " 'song16.txt',\n",
       " 'song17.txt',\n",
       " 'song18.txt',\n",
       " 'song19.txt',\n",
       " 'song20.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [f'song{str(i)}.txt' for i in range(1,21)] \n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using list comprehension to create a list containing the name of every single song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[Kendrick Lamar:]\\n',\n",
       " \"Two wrongs don't make us right away\\n\",\n",
       " \"Tell me something's wrong\\n\",\n",
       " 'Party all of our lives away\\n',\n",
       " 'To take you on\\n',\n",
       " '[Zacari:]\\n',\n",
       " 'Oh, baby I want you\\n',\n",
       " 'Baby I need you\\n',\n",
       " 'I wanna see you\\n',\n",
       " 'Baby I wanna go out yeah\\n',\n",
       " 'Baby I wanna go out yeah\\n',\n",
       " 'Baby I want you\\n',\n",
       " 'Baby I need you\\n',\n",
       " 'I wanna see you\\n',\n",
       " 'Baby I wanna go out yeah\\n',\n",
       " 'Baby I wanna go out yeah\\n',\n",
       " 'All night (all night, all night)\\n',\n",
       " 'All night\\n',\n",
       " \"Your body's on fire\\n\",\n",
       " 'And your drinks on ice\\n',\n",
       " 'All night (all night, all night)\\n',\n",
       " 'All night\\n',\n",
       " \"Your body's on fire\\n\",\n",
       " 'And your drinks on ice\\n',\n",
       " '[Babes Wodumo:]\\n',\n",
       " 'Oh my word oh my gosh oh my word (Oh my gosh)\\n',\n",
       " 'Oh my word oh my gosh oh my word (Oh my gosh)\\n',\n",
       " 'Oh my word oh my gosh oh my word (Oh my gosh)\\n',\n",
       " 'Oh my word oh my gosh oh my word (Oh my gosh)\\n',\n",
       " 'Everybody say kikiritikiki (kikiritikiki)\\n',\n",
       " 'Everybody say kikiritikiki (kikiritikiki)\\n',\n",
       " 'Everybody say kikiritikiki (kikiritikiki)\\n',\n",
       " 'Everybody say kikiritikiki (kikiritikiki)\\n',\n",
       " \"Ung'bambe, ung'dedele. Ung'bhasobhe, ung'gudluke\\n\",\n",
       " \"Ung'bambe, ung'dedele. Ung'bhasobhe, ung'gudluke\\n\",\n",
       " \"Ung'bambe, ung'dedele. Ung'bhasobhe, ung'gudluke\\n\",\n",
       " \"Ung'bambe, ung'dedele. Ung'bhasobhe, ung'gudluke\\n\",\n",
       " '[Zacari:]\\n',\n",
       " 'Baby I want you\\n',\n",
       " 'Baby I need you\\n',\n",
       " 'I wanna see you\\n',\n",
       " 'Baby I wanna go out yeah\\n',\n",
       " 'Baby I wanna go out yeah\\n',\n",
       " 'Baby I want you\\n',\n",
       " 'Baby I need you\\n',\n",
       " 'I wanna see you\\n',\n",
       " 'Baby I wanna go out yeah\\n',\n",
       " 'Baby I wanna go out yeah\\n',\n",
       " 'All night (all night all night)\\n',\n",
       " 'All night\\n',\n",
       " \"Your body's on fire\\n\",\n",
       " 'And your drinks on ice\\n',\n",
       " 'All night (all night all night)\\n',\n",
       " 'All night\\n',\n",
       " \"Your body's on fire\\n\",\n",
       " 'And your drinks on ice\\n',\n",
       " '[Kendrick Lamar:]\\n',\n",
       " '(We go)\\n',\n",
       " 'High up (High up)\\n',\n",
       " 'High up (High up)\\n',\n",
       " 'High up (High up)\\n',\n",
       " 'High up (High up)\\n',\n",
       " 'High up (High up)\\n',\n",
       " 'High up (High up)\\n',\n",
       " 'High up (High up)\\n',\n",
       " 'High up (High up)\\n',\n",
       " '[?]\\n',\n",
       " '[Zacari:]\\n',\n",
       " 'Baby I want you\\n',\n",
       " 'Baby I need you\\n',\n",
       " 'I wanna see you\\n',\n",
       " 'Baby I wanna go out yeah\\n',\n",
       " 'Baby I wanna go out yeah\\n',\n",
       " 'Baby I want you\\n',\n",
       " 'Baby I need you\\n',\n",
       " 'I wanna see you\\n',\n",
       " 'Baby I wanna go out yeah\\n',\n",
       " 'Baby I wanna go out yeah\\n',\n",
       " 'All night (all night all night)\\n',\n",
       " 'All night\\n',\n",
       " \"Your body's on fire\\n\",\n",
       " 'And your drinks on ice\\n',\n",
       " 'All night (all night all night)\\n',\n",
       " 'All night\\n',\n",
       " \"Your body's on fire\\n\",\n",
       " 'And your drinks on ice\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/song18.txt') as f:\n",
    "    test_song = f.readlines() \n",
    "test_song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizing our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two wrongs dont make us right away  tell me somethings wrong  party all of our lives away  to take you on  oh baby i want you  baby i need you  i wanna see you  baby i wanna go out yeah  baby i wanna go out yeah  baby i want you  baby i need you  i wanna see you  baby i wanna go out yeah  baby i wanna go out yeah  all night all night all night  all night  your bodys on fire  and your drinks on ice  all night all night all night  all night  your bodys on fire  and your drinks on ice  oh my word oh my gosh oh my word oh my gosh  oh my word oh my gosh oh my word oh my gosh  oh my word oh my gosh oh my word oh my gosh  oh my word oh my gosh oh my word oh my gosh  everybody say kikiritikiki kikiritikiki  everybody say kikiritikiki kikiritikiki  everybody say kikiritikiki kikiritikiki  everybody say kikiritikiki kikiritikiki  ungbambe ungdedele ungbhasobhe unggudluke  ungbambe ungdedele ungbhasobhe unggudluke  ungbambe ungdedele ungbhasobhe unggudluke  ungbambe ungdedele ungbhasobhe unggudluke  baby i want you  baby i need you  i wanna see you  baby i wanna go out yeah  baby i wanna go out yeah  baby i want you  baby i need you  i wanna see you  baby i wanna go out yeah  baby i wanna go out yeah  all night all night all night  all night  your bodys on fire  and your drinks on ice  all night all night all night  all night  your bodys on fire  and your drinks on ice  we go  high up high up  high up high up  high up high up  high up high up  high up high up  high up high up  high up high up  high up high up  baby i want you  baby i need you  i wanna see you  baby i wanna go out yeah  baby i wanna go out yeah  baby i want you  baby i need you  i wanna see you  baby i wanna go out yeah  baby i wanna go out yeah  all night all night all night  all night  your bodys on fire  and your drinks on ice  all night all night all night  all night  your bodys on fire  and your drinks on ice \n"
     ]
    }
   ],
   "source": [
    "def clean_song(song):\n",
    "    clean_lines = [line for line in song if \"[\" not in line and \"]\" not in line]\n",
    "    clean_song = \" \".join(clean_lines)\n",
    "    for symbol in \",.'?!()\":\n",
    "        clean_song = clean_song.replace(symbol, \"\")\n",
    "    clean_song = clean_song.replace(\"\\n\", \" \")\n",
    "    return clean_song.lower()\n",
    "    \n",
    "clean_test_song = clean_song(test_song)\n",
    "print(clean_test_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['two',\n",
       " 'wrongs',\n",
       " 'dont',\n",
       " 'make',\n",
       " 'us',\n",
       " 'right',\n",
       " 'away',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'somethings',\n",
       " 'wrong',\n",
       " 'party',\n",
       " 'all',\n",
       " 'of',\n",
       " 'our',\n",
       " 'lives',\n",
       " 'away',\n",
       " 'to',\n",
       " 'take',\n",
       " 'you',\n",
       " 'on',\n",
       " 'oh',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'want',\n",
       " 'you',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'need',\n",
       " 'you',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'see',\n",
       " 'you',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'go',\n",
       " 'out',\n",
       " 'yeah',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'go',\n",
       " 'out',\n",
       " 'yeah',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'want',\n",
       " 'you',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'need',\n",
       " 'you',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'see',\n",
       " 'you',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'go',\n",
       " 'out',\n",
       " 'yeah',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'go',\n",
       " 'out',\n",
       " 'yeah',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'your',\n",
       " 'bodys',\n",
       " 'on',\n",
       " 'fire',\n",
       " 'and',\n",
       " 'your',\n",
       " 'drinks',\n",
       " 'on',\n",
       " 'ice',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'your',\n",
       " 'bodys',\n",
       " 'on',\n",
       " 'fire',\n",
       " 'and',\n",
       " 'your',\n",
       " 'drinks',\n",
       " 'on',\n",
       " 'ice',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'word',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'gosh',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'word',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'gosh',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'word',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'gosh',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'word',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'gosh',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'word',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'gosh',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'word',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'gosh',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'word',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'gosh',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'word',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'gosh',\n",
       " 'everybody',\n",
       " 'say',\n",
       " 'kikiritikiki',\n",
       " 'kikiritikiki',\n",
       " 'everybody',\n",
       " 'say',\n",
       " 'kikiritikiki',\n",
       " 'kikiritikiki',\n",
       " 'everybody',\n",
       " 'say',\n",
       " 'kikiritikiki',\n",
       " 'kikiritikiki',\n",
       " 'everybody',\n",
       " 'say',\n",
       " 'kikiritikiki',\n",
       " 'kikiritikiki',\n",
       " 'ungbambe',\n",
       " 'ungdedele',\n",
       " 'ungbhasobhe',\n",
       " 'unggudluke',\n",
       " 'ungbambe',\n",
       " 'ungdedele',\n",
       " 'ungbhasobhe',\n",
       " 'unggudluke',\n",
       " 'ungbambe',\n",
       " 'ungdedele',\n",
       " 'ungbhasobhe',\n",
       " 'unggudluke',\n",
       " 'ungbambe',\n",
       " 'ungdedele',\n",
       " 'ungbhasobhe',\n",
       " 'unggudluke',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'want',\n",
       " 'you',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'need',\n",
       " 'you',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'see',\n",
       " 'you',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'go',\n",
       " 'out',\n",
       " 'yeah',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'go',\n",
       " 'out',\n",
       " 'yeah',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'want',\n",
       " 'you',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'need',\n",
       " 'you',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'see',\n",
       " 'you',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'go',\n",
       " 'out',\n",
       " 'yeah',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'go',\n",
       " 'out',\n",
       " 'yeah',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'your',\n",
       " 'bodys',\n",
       " 'on',\n",
       " 'fire',\n",
       " 'and',\n",
       " 'your',\n",
       " 'drinks',\n",
       " 'on',\n",
       " 'ice',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'your',\n",
       " 'bodys',\n",
       " 'on',\n",
       " 'fire',\n",
       " 'and',\n",
       " 'your',\n",
       " 'drinks',\n",
       " 'on',\n",
       " 'ice',\n",
       " 'we',\n",
       " 'go',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'high',\n",
       " 'up',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'want',\n",
       " 'you',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'need',\n",
       " 'you',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'see',\n",
       " 'you',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'go',\n",
       " 'out',\n",
       " 'yeah',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'go',\n",
       " 'out',\n",
       " 'yeah',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'want',\n",
       " 'you',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'need',\n",
       " 'you',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'see',\n",
       " 'you',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'go',\n",
       " 'out',\n",
       " 'yeah',\n",
       " 'baby',\n",
       " 'i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'go',\n",
       " 'out',\n",
       " 'yeah',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'your',\n",
       " 'bodys',\n",
       " 'on',\n",
       " 'fire',\n",
       " 'and',\n",
       " 'your',\n",
       " 'drinks',\n",
       " 'on',\n",
       " 'ice',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'all',\n",
       " 'night',\n",
       " 'your',\n",
       " 'bodys',\n",
       " 'on',\n",
       " 'fire',\n",
       " 'and',\n",
       " 'your',\n",
       " 'drinks',\n",
       " 'on',\n",
       " 'ice']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test_song= word_tokenize(clean_test_song) \n",
    "tokenized_test_song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unggudluke': 4, 'word': 8, 'everybody': 4, 'me': 1, 'need': 6, 'us': 1, 'lives': 1, 'ice': 6, 'oh': 17, 'kikiritikiki': 8, 'all': 25, 'tell': 1, 'right': 1, 'go': 13, 'want': 6, 'and': 6, 'bodys': 6, 'ungbambe': 4, 'take': 1, 'fire': 6, 'gosh': 8, 'party': 1, 'baby': 24, 'dont': 1, 'wrongs': 1, 'of': 1, 'i': 30, 'your': 12, 'see': 6, 'wan': 18, 'ungdedele': 4, 'to': 1, 'night': 24, 'up': 16, 'you': 19, 'out': 12, 'two': 1, 'wrong': 1, 'high': 16, 'ungbhasobhe': 4, 'say': 4, 'make': 1, 'my': 16, 'yeah': 12, 'away': 2, 'somethings': 1, 'na': 18, 'our': 1, 'we': 1, 'on': 13, 'drinks': 6}\n"
     ]
    }
   ],
   "source": [
    "def count_vectorize(tokenized_song):\n",
    "    unique_words = set(tokenized_song)\n",
    "\n",
    "    song_dict = {word:0 for word in unique_words}\n",
    "\n",
    "    for word in tokenized_song:\n",
    "        song_dict[word] += 1\n",
    "\n",
    "    return song_dict\n",
    "\n",
    "test_vectorized = count_vectorize(tokenized_test_song)\n",
    "print(test_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF(term frequency,inverse document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_document_frequency(list_of_token_songs):\n",
    "    num_docs = len(list_of_token_songs)\n",
    "    unique_words = set([item for sublist in list_of_token_songs for item in sublist])\n",
    "    inv_doc_freq = {word:0 for word in unique_words}\n",
    "    for word in unique_words:\n",
    "        num_docs_with_word = 0\n",
    "        for song_tokens in list_of_token_songs:\n",
    "            if word in song_tokens:\n",
    "                num_docs_with_word += 1\n",
    "        inv_doc_freq[word] = np.log(num_docs / num_docs_with_word)\n",
    "    return inv_doc_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(list_of_token_songs):\n",
    "    \n",
    "    unique_words = set([item for sublist in list_of_token_songs for item in sublist])\n",
    "    \n",
    "    idf = inverse_document_frequency(list_of_token_songs)\n",
    "    \n",
    "    tf_idf_list_of_dicts = []\n",
    "    for song_tokens in list_of_token_songs:\n",
    "        song_tf = count_vectorize(song_tokens)\n",
    "        doc_tf_idf = {word:0 for word in unique_words}\n",
    "        for word in unique_words:\n",
    "            if word in song_tokens:\n",
    "                doc_tf_idf[word] = song_tf[word] * idf[word]\n",
    "            else:\n",
    "                doc_tf_idf[word] = 0\n",
    "        tf_idf_list_of_dicts.append(doc_tf_idf)\n",
    "        \n",
    "    return tf_idf_list_of_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorizing the whole document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(filenames):\n",
    "    \n",
    "    all_songs = []\n",
    "    for song in filenames:\n",
    "        with open(f'data/{song}') as f:\n",
    "            song_lyrics = f.readlines()\n",
    "            all_songs.append(song_lyrics)\n",
    "    \n",
    "    all_song_tokens = []\n",
    "\n",
    "    for song in all_songs:\n",
    "        song_tokens = word_tokenize(clean_song(song))\n",
    "        all_song_tokens.append(song_tokens)\n",
    "\n",
    "    tf_idf_all_docs = tf_idf(all_song_tokens)\n",
    "    return tf_idf_all_docs\n",
    "\n",
    "tf_idf_all_docs = main(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualizing our vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dimensions: 1343\n"
     ]
    }
   ],
   "source": [
    "vocab = list(tf_idf_all_docs[0].keys())\n",
    "num_dims = len(vocab)\n",
    "print(f\"Number of Dimensions: {num_dims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are many dimension and should be reduced to 3 or 2 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE(t-Stochastic Neighbors Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 11.982929094215963, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vals_list = []\n",
    "\n",
    "for i in tf_idf_all_docs:\n",
    "    tf_idf_vals_list.append(list(i.values()))\n",
    "    \n",
    "tf_idf_vals_list[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transforming to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  20.988451,  162.2916  , -339.3311  ],\n",
       "       [-181.98544 , -142.59947 ,  220.85582 ],\n",
       "       [ -49.524933,  142.6596  ,  671.67285 ],\n",
       "       [-361.52716 ,   70.680954, -132.90608 ],\n",
       "       [ -81.63559 , -292.24158 , -101.59032 ],\n",
       "       [ 184.64783 , -221.82283 , -107.70265 ],\n",
       "       [-149.02028 ,  113.712395,  156.49574 ],\n",
       "       [ 311.8493  ,   41.677105,  -13.131188],\n",
       "       [ 102.19527 ,  -72.20597 ,  103.7679  ],\n",
       "       [  -3.099688, -112.23449 , -284.36935 ],\n",
       "       [ 163.0125  ,  260.00797 , -118.294365],\n",
       "       [-364.8224  , -267.11127 , -208.41284 ],\n",
       "       [ 373.1391  , -166.58722 ,  126.24301 ],\n",
       "       [-132.31361 ,  299.75308 ,  -15.877989],\n",
       "       [-130.73271 ,   98.06246 , -163.92964 ],\n",
       "       [-147.25543 ,  -81.70149 ,   -9.858946],\n",
       "       [  96.80208 ,  132.22455 ,  211.94019 ],\n",
       "       [  40.25879 , -303.09598 ,  141.53294 ],\n",
       "       [  88.8828  ,   38.8251  , -106.25811 ],\n",
       "       [ 125.37611 ,  206.32574 ,  447.4433  ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_sne_object_3d = TSNE(n_components = 3, \n",
    "                       perplexity = 19,\n",
    "                       learning_rate = 200,\n",
    "                       init = 'random',\n",
    "                       random_state = 13)\n",
    "\n",
    "transformed_data_3d = t_sne_object_3d.fit_transform(np.array(tf_idf_vals_list))\n",
    "transformed_data_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  50.12471  , -121.04354  ],\n",
       "       [   2.2767437,  -16.84815  ],\n",
       "       [  87.871155 ,  -60.420795 ],\n",
       "       [ -35.132103 ,   66.9128   ],\n",
       "       [  76.76955  ,   62.21425  ],\n",
       "       [  27.01112  ,  103.58503  ],\n",
       "       [ -90.130455 ,   36.102116 ],\n",
       "       [ -83.411285 ,  -25.650719 ],\n",
       "       [ -20.020597 , -121.22999  ],\n",
       "       [ -83.30488  , -102.698685 ],\n",
       "       [ -37.67552  ,  -58.70705  ],\n",
       "       [ 115.2907   ,    5.731269 ],\n",
       "       [-133.99341  ,  -58.743423 ],\n",
       "       [  15.45905  ,   40.39115  ],\n",
       "       [ -40.38645  ,   10.628868 ],\n",
       "       [ -36.832195 ,  126.709236 ],\n",
       "       [-102.84165  ,   94.32765  ],\n",
       "       [  55.10724  ,   -4.15992  ],\n",
       "       [-145.55449  ,   12.449843 ],\n",
       "       [  22.668291 ,  -66.50144  ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_sne_object_2d = TSNE(n_components = 2, \n",
    "                       perplexity = 19,\n",
    "                       learning_rate = 200,\n",
    "                       init = 'random', \n",
    "                       random_state = 13)\n",
    "transformed_data_2d = t_sne_object_2d.fit_transform(np.array(tf_idf_vals_list))\n",
    "transformed_data_2d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
